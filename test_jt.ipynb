{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import jittor as jt\n",
    "from jittor import Module\n",
    "from jittor import nn\n",
    "from jittor.dataset.mnist import MNIST\n",
    "import jittor.transform as trans\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.use('TkAgg')\n",
    "\n",
    "jt.flags.use_cuda = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = MNIST(train=True, transform=trans.Resize(28)).set_attrs(batch_size=batch_size, shuffle=True)\n",
    "val_loader = MNIST(train=False, transform=trans.Resize(28)).set_attrs(batch_size=batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape:  [64,3,28,28,]\n",
      "targets.shape:  [64,]\n",
      "target:  7\n"
     ]
    }
   ],
   "source": [
    "num = 0\n",
    "for inputs, targets in val_loader:\n",
    "    print(\"inputs.shape: \", inputs.shape)\n",
    "    print(\"targets.shape: \", targets.shape)\n",
    "    plt.imshow(inputs[num].numpy().transpose(1, 2, 0))\n",
    "    print(\"target: \", targets[num].data[0])\n",
    "    plt.show()\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class Model(Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv(3, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv(32, 64, 3, 1)\n",
    "        self.bn = nn.BatchNorm(64)\n",
    "        self.max_pool = nn.Pool(2, 2)\n",
    "        self.relu = nn.Relu()\n",
    "        self.fc1 = nn.Linear(64 * 12 * 12, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def execute(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool(x)\n",
    "        x = jt.reshape(x, [x.shape[0], -1])\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "model = Model()\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = nn.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def train(model, train_loader, loss_function, optimizer, epoch):\n",
    "    model.train()\n",
    "    train_losses = list()\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        optimizer.step(loss)\n",
    "        train_losses.append(loss)\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx, len(train_loader), 100. * batch_idx / len(train_loader), loss.data[0]\n",
    "            ))\n",
    "    return train_losses\n",
    "\n",
    "\n",
    "def test(model, val_loader, loss_function, epoch):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_num = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "        outputs = model(inputs)\n",
    "        pred = np.argmax(outputs.data, axis=1)\n",
    "        correct = np.sum(targets.data == pred)\n",
    "\n",
    "        total_correct += correct\n",
    "        total_num += inputs.shape[0]\n",
    "    test_acc = total_correct / total_num\n",
    "    print(\"Test Accuracy: \", test_acc)\n",
    "    return test_acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/938 (0%)]\tLoss: 0.002558\n",
      "Train Epoch: 0 [100/938 (11%)]\tLoss: 0.000557\n",
      "Train Epoch: 0 [200/938 (21%)]\tLoss: 0.001438\n",
      "Train Epoch: 0 [300/938 (32%)]\tLoss: 0.009184\n",
      "Train Epoch: 0 [400/938 (43%)]\tLoss: 0.002049\n",
      "Train Epoch: 0 [500/938 (53%)]\tLoss: 0.001760\n",
      "Train Epoch: 0 [600/938 (64%)]\tLoss: 0.001933\n",
      "Train Epoch: 0 [700/938 (75%)]\tLoss: 0.000305\n",
      "Train Epoch: 0 [800/938 (85%)]\tLoss: 0.001223\n",
      "Train Epoch: 0 [900/938 (96%)]\tLoss: 0.000471\n",
      "Test Accuracy:  0.9919\n",
      "Train Epoch: 1 [0/938 (0%)]\tLoss: 0.018438\n",
      "Train Epoch: 1 [100/938 (11%)]\tLoss: 0.000829\n",
      "Train Epoch: 1 [200/938 (21%)]\tLoss: 0.003311\n",
      "Train Epoch: 1 [300/938 (32%)]\tLoss: 0.005453\n",
      "Train Epoch: 1 [400/938 (43%)]\tLoss: 0.000502\n",
      "Train Epoch: 1 [500/938 (53%)]\tLoss: 0.003667\n",
      "Train Epoch: 1 [600/938 (64%)]\tLoss: 0.000083\n",
      "Train Epoch: 1 [700/938 (75%)]\tLoss: 0.003584\n",
      "Train Epoch: 1 [800/938 (85%)]\tLoss: 0.007908\n",
      "Train Epoch: 1 [900/938 (96%)]\tLoss: 0.000255\n",
      "Test Accuracy:  0.9916\n",
      "Train Epoch: 2 [0/938 (0%)]\tLoss: 0.000116\n",
      "Train Epoch: 2 [100/938 (11%)]\tLoss: 0.000666\n",
      "Train Epoch: 2 [200/938 (21%)]\tLoss: 0.000221\n",
      "Train Epoch: 2 [300/938 (32%)]\tLoss: 0.009564\n",
      "Train Epoch: 2 [400/938 (43%)]\tLoss: 0.006412\n",
      "Train Epoch: 2 [500/938 (53%)]\tLoss: 0.006204\n",
      "Train Epoch: 2 [600/938 (64%)]\tLoss: 0.030739\n",
      "Train Epoch: 2 [700/938 (75%)]\tLoss: 0.002772\n",
      "Train Epoch: 2 [800/938 (85%)]\tLoss: 0.000089\n",
      "Train Epoch: 2 [900/938 (96%)]\tLoss: 0.001259\n",
      "Test Accuracy:  0.9915\n",
      "Train Epoch: 3 [0/938 (0%)]\tLoss: 0.002540\n",
      "Train Epoch: 3 [100/938 (11%)]\tLoss: 0.000112\n",
      "Train Epoch: 3 [200/938 (21%)]\tLoss: 0.059537\n",
      "Train Epoch: 3 [300/938 (32%)]\tLoss: 0.000039\n",
      "Train Epoch: 3 [400/938 (43%)]\tLoss: 0.000251\n",
      "Train Epoch: 3 [500/938 (53%)]\tLoss: 0.000014\n",
      "Train Epoch: 3 [600/938 (64%)]\tLoss: 0.019645\n",
      "Train Epoch: 3 [700/938 (75%)]\tLoss: 0.000054\n",
      "Train Epoch: 3 [800/938 (85%)]\tLoss: 0.000186\n",
      "Train Epoch: 3 [900/938 (96%)]\tLoss: 0.000035\n",
      "Test Accuracy:  0.9922\n",
      "Train Epoch: 4 [0/938 (0%)]\tLoss: 0.000084\n",
      "Train Epoch: 4 [100/938 (11%)]\tLoss: 0.001406\n",
      "Train Epoch: 4 [200/938 (21%)]\tLoss: 0.000200\n",
      "Train Epoch: 4 [300/938 (32%)]\tLoss: 0.000688\n",
      "Train Epoch: 4 [400/938 (43%)]\tLoss: 0.000415\n",
      "Train Epoch: 4 [500/938 (53%)]\tLoss: 0.000201\n",
      "Train Epoch: 4 [600/938 (64%)]\tLoss: 0.000042\n",
      "Train Epoch: 4 [700/938 (75%)]\tLoss: 0.001554\n",
      "Train Epoch: 4 [800/938 (85%)]\tLoss: 0.000070\n",
      "Train Epoch: 4 [900/938 (96%)]\tLoss: 0.002415\n",
      "Test Accuracy:  0.9924\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "train_losses = list()\n",
    "test_acc = list()\n",
    "for epoch in range(epochs):\n",
    "    loss = train(model, train_loader, loss_func, optimizer, epoch)\n",
    "    acc = test(model, val_loader, loss_func, epoch)\n",
    "    train_losses += loss\n",
    "    test_acc.append(acc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\Python310\\lib\\site-packages\\numpy\\core\\shape_base.py:65: FutureWarning: The input object of type 'jittor_core.Var' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'jittor_core.Var', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  ary = asanyarray(ary)\n",
      "D:\\Python\\Python310\\lib\\site-packages\\numpy\\core\\shape_base.py:65: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  ary = asanyarray(ary)\n"
     ]
    }
   ],
   "source": [
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "plt.plot(test_acc, label=\"Test Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target:  4\n",
      "prediction:  4\n"
     ]
    }
   ],
   "source": [
    "num = 6\n",
    "for inputs, targets in val_loader:\n",
    "    plt.imshow(inputs[num].numpy().transpose(1, 2, 0))\n",
    "    plt.show()\n",
    "\n",
    "    print(\"target: \", targets[num].data[0])\n",
    "\n",
    "    outputs = model(inputs)\n",
    "    pred = np.argmax(outputs.data, axis=1)\n",
    "    print(\"prediction: \", pred[num])\n",
    "\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}